---
title: "07. Email"
author: "Jing Xie"
date: "11/20/2021"
output: rmarkdown::github_document
---
You are in charge of figuring out how the email campaign performed and were asked the
following questions:
1. What percentage of users opened the email and what percentage clicked on the link within the email?
2. The VP of marketing thinks that it is stupid to send emails to a random subset and in a random way. Based on all the information you have about the emails that were sent, can you build a model to optimize in future email campaigns to maximize the probability of users clicking on the link inside the email?
3. By how much do you think your model would improve click through rate ( defined as # of users who click on the link / total users who received the email). How would you test that?
4. Did you find any interesting pattern on how the email campaign performed for different segments of users? Explain.
# Input libraries needed
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(randomForest)
library(ROCR)
library(rpart)
library(ROSE)
library(ggplot2)
library(rpart.plot)
```

# Input data
```{r}
email_data = read.csv('email_table.csv')
email_open = read.csv('email_opened_table.csv')
link_click = read.csv('link_clicked_table.csv')
#are there duplicates?
nrow(email_data) == length(unique(email_data$email_id))
nrow(email_open) == length(unique(email_open$email_id))
nrow(link_click) == length(unique(link_click$email_id))
# No duplicates
# Are there any missing values?
sum(is.na(email_data))
sum(is.na(email_open))
sum(is.na(link_click))
# No missing values
```
# Add two new columns email_data to indicate email_open and link_click.
# Work out the percentage of users opened the email and clicked on the link within the email.
```{r}
email_data$email_open = ifelse(email_data$email_id %in% email_open$email_id,
                               1, 0 )
email_data$link_click = ifelse(email_data$email_id %in% link_click$email_id,
                               1, 0 )

link_click %>% filter((link_click$email_id %in% email_open$email_id) ==FALSE )
# There are 50 link clicks that don't open email open firstly, which is weird.

sum(email_data$email_open)/length(email_data$email_id)
sum(email_data$link_click)/sum(email_data$email_open)
sum(email_data$link_click)/length(email_data$email_id)
```
10.345% of all the emails sent will be opened to read
20.48% of all opened emails, the link will be clicked to direct to the website.
2.119% of all the emails sent, the link will be clicked.

# Build a model to find out the probabilty of click the email based on user characteristic
# Have a look at the data file
```{r}
summary(email_data)
email_data$email_text = as.factor(email_data$email_text)
email_data$email_version= as.factor(email_data$email_version)
email_data$weekday= as.factor(email_data$weekday)
email_data$user_country= as.factor(email_data$user_country)
email_data$email_open= as.factor(email_data$email_open)
email_data$link_click= as.factor(email_data$link_click)
```

# Split train and test dataset and build a model
```{r}
train_sample = sample(nrow(email_data), size = nrow(email_data)*0.7)
train_data = email_data[train_sample,]
test_data = email_data[-train_sample,]

# Deal with imbalance data
table(email_data$link_click)
prop.table(table(email_data$link_click))
# The original data is highly imbalanced.

bal_train_data <- ROSE(link_click ~ ., data=train_data,seed=5)$data
bal_train_data <- bal_train_data[,-c(1,8)]
table(bal_train_data$link_click)
prop.table(table(bal_train_data$link_click))

rf = randomForest(y=bal_train_data$link_click,
                  x = bal_train_data[,-7],
                  ytest = test_data$link_click, 
                  xtest = test_data[, c(2:7)],
                  ntree = 50, mtry = 3, keep.forest = TRUE) 
rf

```


```{r}
#this creates an object with all the information you can possibly need about how
# different cutoff values impact all possible metrics: true positive, true 
# negative, false positive, false negative...
rf_results = data.frame (true_values = test_data$link_click,predictions = rf$test$votes[,2])
pred = prediction(rf_results$predictions, rf_results$true_values)
#now let's just plot the ROC and look at true positive vs false positive
perf = performance (pred, measure = 'tpr', x.measure = "fpr")
plot(perf) + abline(a=0, b=1, col = 'red') # the red line is randomness
```
```{r}
auc_ROCR <- performance(pred, measure = "auc")
print(auc_ROCR@y.values[[1]])
```
There is only 0.557771 AUC, very bad
After balancing data, AUC becomes 0.69

# By how much do you think your model would improve click through rate ( defined as # of users who click on the link / total users who received the email). How would you test that?
```{r}
old_ctr = sum(email_data$link_click==1)/length(email_data$email_id)
old_ctr
# Use LIFT to measure!!
# Make Cumulative Response Curve - Use Definition
test_cr = test_data %>% 
  mutate(prob = rf_results$predictions) %>%
  arrange(desc(prob)) %>%
  mutate(click_yes = link_click) %>%
# the following two lines make the cumulative response curve 
  mutate(y = cumsum(click_yes==1)/sum(click_yes==1),
         x = row_number()/nrow(test_data))
# Then, simply plot it.
ggplot(data = test_cr, aes(x = x, y = y)) + geom_line() + theme_bw()

# Plot lift
test_lift = test_data %>%
  mutate(prob = rf_results$predictions) %>% 
  arrange(desc(prob)) %>%
  mutate(click_yes = link_click) %>% 
  # the following two lines make the lift curve 
  mutate(x = row_number()/nrow(test_data),
         y = (cumsum(click_yes==1)/sum(click_yes==1))/x)
# Then, simply plot it.
ggplot(data = test_lift, aes(x = x, y = y)) + geom_line() +
  theme_bw()

pred$predictions
predictions
```

Old click through rate = 2%
So comparing with randomly selected email pools, this model would improve click through rate by more than 2 times sending emails to top 25% users that has highest probability to click the link that predicted by this model.

More precisely, we can conduct a A/B Test to see whether the prediction model actually help increase the click through rate.

# 4. Did you find any interesting pattern on how the email campaign performed for different segments of users? Explain.

```{r}
# Check variance importance:
varImpPlot(rf,type=2)
```

# Letâ€™s check partial dependence plots:
```{r}
op <- par(mfrow=c(3, 3)) # Put below 6 plots in a 3*3 grid.
partialPlot(rf, train_data, user_past_purchases, 1) 
partialPlot(rf, train_data, hour, 1)
partialPlot(rf, train_data, weekday, 1)
partialPlot(rf, train_data, user_country, 1)
partialPlot(rf, train_data, email_version, 1)
partialPlot(rf, train_data, email_text, 1)
```
From the partial dependence plot, we can see that:
1. users that have more purchases in the past, is more likely to click the link, probably indicating that we need to send emails focusing on the old, loyal customers.
2. 10 am peaks on the CTR, we might change our sending email time to 10AM.
3. Email sent at weekday(middle of the week) has higher CTR compared with weekends!
4. UK and US have significantly higher CTR compared with other countries, so we can put more priority to these two countries.
5. Personalized and short email is more attractive to customers to click.

```{r}
tree = rpart(train_data$link_click ~ ., train_data[,c(2:7)],
             control = list(maxdepth = 5,
                            cp = 0.002), # Complexity parameter!!
             parms = list(prior = c(0.7, 0.3)))
tree
```


```{r}
prp(tree, varlen = 0)
```
Same patten as we saw in random forest partial dependence plot.
# 4. Did you find any interesting pattern on how the email campaign performed for different segments of users? Explain.

So there can be segments like: 
US/UK and ES/FR: US/UK has much higher CTR through the email campaign
Loyal users: Users purchases more than 9 items are very likely to click the link in the email campaign.

